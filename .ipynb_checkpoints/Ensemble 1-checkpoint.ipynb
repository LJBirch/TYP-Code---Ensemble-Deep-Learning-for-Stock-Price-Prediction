{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Activation, Dropout, LSTM, GRU, RNN, SimpleRNNCell, Input, Flatten\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error, recall_score, precision_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in data from CSV.\n",
    "df = pd.read_csv(\"./data/source_price_alt.csv\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert index to date.\n",
    "df.index = df.date;\n",
    "df.drop('date', axis=1, inplace = True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract adjusted close column.\n",
    "adjust_close = df.iloc[:,-1].values; \n",
    "\n",
    "# Normalize adjusted close data.\n",
    "scaler = MinMaxScaler();\n",
    "scaled_adjust_close = scaler.fit_transform(adjust_close.reshape(-1,1));\n",
    "\n",
    "# Remove un-normalized column.\n",
    "source_data = df.drop(['Adj Close'], axis=1)\n",
    "\n",
    "# Set new column with normalized data.\n",
    "source_data[\"scaled_adj_close\"] = scaled_adjust_close"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into train test split.\n",
    "train_validation_data, test_data = train_test_split(source_data, train_size=0.85, test_size=0.15, shuffle = False);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "validation_data = train_validation_data[83:];\n",
    "train_data = train_validation_data[:83];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into input X and output Y, by splitting into 'n' past days as input X and `m` coming days as Y.\n",
    "def processData(data, look_back, forward_days,jump=1):\n",
    "    A,B = [],[]\n",
    "    for i in range(0,len(data) - look_back, jump):\n",
    "        A.append(data[i:(i + look_back)])\n",
    "        B.append(data[(i + look_back):(i + look_back + forward_days)])\n",
    "    return np.array(A), np.array(B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set model configurations.\n",
    "look_back = 5\n",
    "forward_days = 1\n",
    "NUM_NEURONS = 50\n",
    "EPOCHES = 100\n",
    "BATCH_SIZE = 32\n",
    "DROUP_OUT = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into past and coming days.\n",
    "m_training_data = train_data.to_numpy()\n",
    "m_validation_data = validation_data.to_numpy()\n",
    "m_test_data = test_data.to_numpy()\n",
    "\n",
    "X_train, Y_train = processData(m_training_data, look_back, forward_days)\n",
    "X_validation, Y_validation = processData(m_validation_data, look_back, forward_days)\n",
    "X_test, Y_test = processData(m_test_data, look_back, forward_days)\n",
    "\n",
    "Y_train = Y_train[:,0,-1]\n",
    "Y_validation = Y_validation[:,0,-1]\n",
    "Y_test = Y_test[:,0,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "3/3 [==============================] - 7s 9ms/step - loss: 0.2670\n",
      "Epoch 2/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.2343\n",
      "Epoch 3/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.1920\n",
      "Epoch 4/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.1354\n",
      "Epoch 5/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.0771\n",
      "Epoch 6/100\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.0433\n",
      "Epoch 7/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.0679\n",
      "Epoch 8/100\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.0616\n",
      "Epoch 9/100\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.0466\n",
      "Epoch 10/100\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.0463\n",
      "Epoch 11/100\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.0481\n",
      "Epoch 12/100\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.0452\n",
      "Epoch 13/100\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.0384\n",
      "Epoch 14/100\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.0452\n",
      "Epoch 15/100\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 0.0405\n",
      "Epoch 16/100\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.0434\n",
      "Epoch 17/100\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.0408\n",
      "Epoch 18/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.0452\n",
      "Epoch 19/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.0393\n",
      "Epoch 20/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.0358\n",
      "Epoch 21/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.0380\n",
      "Epoch 22/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.0333\n",
      "Epoch 23/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.0307\n",
      "Epoch 24/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.0352\n",
      "Epoch 25/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.0413\n",
      "Epoch 26/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.0364\n",
      "Epoch 27/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.0357\n",
      "Epoch 28/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.0441\n",
      "Epoch 29/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.0327\n",
      "Epoch 30/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.0373\n",
      "Epoch 31/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.0401\n",
      "Epoch 32/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.0352\n",
      "Epoch 33/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.0332\n",
      "Epoch 34/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.0317\n",
      "Epoch 35/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.0353\n",
      "Epoch 36/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.0355\n",
      "Epoch 37/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.0386\n",
      "Epoch 38/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.0320\n",
      "Epoch 39/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.0329\n",
      "Epoch 40/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.0335\n",
      "Epoch 41/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.0244\n",
      "Epoch 42/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.0370\n",
      "Epoch 43/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.0396\n",
      "Epoch 44/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.0357\n",
      "Epoch 45/100\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.0400\n",
      "Epoch 46/100\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 0.0299\n",
      "Epoch 47/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.0306\n",
      "Epoch 48/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.0371\n",
      "Epoch 49/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.0365\n",
      "Epoch 50/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.0404\n",
      "Epoch 51/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.0417\n",
      "Epoch 52/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.0359\n",
      "Epoch 53/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.0313\n",
      "Epoch 54/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.0314\n",
      "Epoch 55/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.0293\n",
      "Epoch 56/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.0388\n",
      "Epoch 57/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.0287\n",
      "Epoch 58/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.0429\n",
      "Epoch 59/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.0362\n",
      "Epoch 60/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.0301\n",
      "Epoch 61/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.0328\n",
      "Epoch 62/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.0330\n",
      "Epoch 63/100\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.0291\n",
      "Epoch 64/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.0307\n",
      "Epoch 65/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.0343\n",
      "Epoch 66/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.0338\n",
      "Epoch 67/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.0339\n",
      "Epoch 68/100\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.0361\n",
      "Epoch 69/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.0316\n",
      "Epoch 70/100\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.0341\n",
      "Epoch 71/100\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.0284\n",
      "Epoch 72/100\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.0315\n",
      "Epoch 73/100\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.0322\n",
      "Epoch 74/100\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.0313\n",
      "Epoch 75/100\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.0288\n",
      "Epoch 76/100\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 0.0360\n",
      "Epoch 77/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.0351\n",
      "Epoch 78/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.0362\n",
      "Epoch 79/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.0307\n",
      "Epoch 80/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.0306\n",
      "Epoch 81/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.0311\n",
      "Epoch 82/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.0261\n",
      "Epoch 83/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.0272\n",
      "Epoch 84/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.0276\n",
      "Epoch 85/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.0315\n",
      "Epoch 86/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.0346\n",
      "Epoch 87/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.0329\n",
      "Epoch 88/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.0329\n",
      "Epoch 89/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.0295\n",
      "Epoch 90/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.0365\n",
      "Epoch 91/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.0263\n",
      "Epoch 92/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.0301\n",
      "Epoch 93/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.0284\n",
      "Epoch 94/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.0285\n",
      "Epoch 95/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.0258\n",
      "Epoch 96/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.0276\n",
      "Epoch 97/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.0285\n",
      "Epoch 98/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.0272\n",
      "Epoch 99/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.0335\n",
      "Epoch 100/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.0318\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x24843585f10>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Setup LSTM Model\n",
    "lstm_model = Sequential()\n",
    "\n",
    "# First Layer\n",
    "lstm_model.add(LSTM(units=NUM_NEURONS, return_sequences = True, input_shape=(X_train.shape[1],X_train.shape[2])))\n",
    "lstm_model.add(Dropout(DROUP_OUT))\n",
    "\n",
    "# Second Layer\n",
    "lstm_model.add(LSTM(units=NUM_NEURONS, return_sequences = True))\n",
    "lstm_model.add(Dropout(DROUP_OUT))\n",
    "\n",
    "# Third Layer\n",
    "lstm_model.add(LSTM(units=NUM_NEURONS, return_sequences = True))\n",
    "lstm_model.add(Dropout(DROUP_OUT))\n",
    "\n",
    "# Fourth Layer\n",
    "lstm_model.add(LSTM(units=NUM_NEURONS))\n",
    "lstm_model.add(Dropout(DROUP_OUT))\n",
    "\n",
    "# Output Layer\n",
    "lstm_model.add(Dense(forward_days))\n",
    "\n",
    "# Train Model\n",
    "lstm_model.compile(loss='mean_squared_error',optimizer='adam')\n",
    "              \n",
    "# Compile     \n",
    "lstm_model.fit(X_train, Y_train, epochs = EPOCHES, batch_size = BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "3/3 [==============================] - 8s 9ms/step - loss: 0.2221\n",
      "Epoch 2/100\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.0408\n",
      "Epoch 3/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.0438\n",
      "Epoch 4/100\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.0614\n",
      "Epoch 5/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.0540\n",
      "Epoch 6/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.0367\n",
      "Epoch 7/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.0372\n",
      "Epoch 8/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.0355\n",
      "Epoch 9/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.0377\n",
      "Epoch 10/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.0490\n",
      "Epoch 11/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.0337\n",
      "Epoch 12/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.0412\n",
      "Epoch 13/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.0305\n",
      "Epoch 14/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.0386\n",
      "Epoch 15/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.0332\n",
      "Epoch 16/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.0572\n",
      "Epoch 17/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.0295\n",
      "Epoch 18/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.0269\n",
      "Epoch 19/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.0378\n",
      "Epoch 20/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.0287\n",
      "Epoch 21/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.0350\n",
      "Epoch 22/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.0323\n",
      "Epoch 23/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.0274\n",
      "Epoch 24/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.0286\n",
      "Epoch 25/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.0344\n",
      "Epoch 26/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.0231\n",
      "Epoch 27/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.0417\n",
      "Epoch 28/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.0307\n",
      "Epoch 29/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.0299\n",
      "Epoch 30/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.0307\n",
      "Epoch 31/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.0424\n",
      "Epoch 32/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.0322\n",
      "Epoch 33/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.0260\n",
      "Epoch 34/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.0236\n",
      "Epoch 35/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.0339\n",
      "Epoch 36/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.0273\n",
      "Epoch 37/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.0336\n",
      "Epoch 38/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.0320\n",
      "Epoch 39/100\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.0247\n",
      "Epoch 40/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.0268\n",
      "Epoch 41/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.0262\n",
      "Epoch 42/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.0291\n",
      "Epoch 43/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.0289\n",
      "Epoch 44/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.0315\n",
      "Epoch 45/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.0380\n",
      "Epoch 46/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.0286\n",
      "Epoch 47/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.0341\n",
      "Epoch 48/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.0258\n",
      "Epoch 49/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.0246\n",
      "Epoch 50/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.0242\n",
      "Epoch 51/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.0225\n",
      "Epoch 52/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.0275\n",
      "Epoch 53/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.0279\n",
      "Epoch 54/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.0293\n",
      "Epoch 55/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.0268\n",
      "Epoch 56/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.0229\n",
      "Epoch 57/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.0231\n",
      "Epoch 58/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.0254\n",
      "Epoch 59/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.0240\n",
      "Epoch 60/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.0218\n",
      "Epoch 61/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.0428\n",
      "Epoch 62/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.0224\n",
      "Epoch 63/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.0191\n",
      "Epoch 64/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.0176\n",
      "Epoch 65/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.0241\n",
      "Epoch 66/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.0187\n",
      "Epoch 67/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.0256\n",
      "Epoch 68/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.0193\n",
      "Epoch 69/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.0178\n",
      "Epoch 70/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.0195\n",
      "Epoch 71/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.0191\n",
      "Epoch 72/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.0239\n",
      "Epoch 73/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.0181\n",
      "Epoch 74/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.0223\n",
      "Epoch 75/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.0223\n",
      "Epoch 76/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.0145\n",
      "Epoch 77/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.0288\n",
      "Epoch 78/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.0182\n",
      "Epoch 79/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.0223\n",
      "Epoch 80/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.0165\n",
      "Epoch 81/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.0195\n",
      "Epoch 82/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.0143\n",
      "Epoch 83/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.0170\n",
      "Epoch 84/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.0225\n",
      "Epoch 85/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.0251\n",
      "Epoch 86/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.0238\n",
      "Epoch 87/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.0166\n",
      "Epoch 88/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.0146\n",
      "Epoch 89/100\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 0.0236\n",
      "Epoch 90/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.0253\n",
      "Epoch 91/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.0139\n",
      "Epoch 92/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.0215\n",
      "Epoch 93/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.0153\n",
      "Epoch 94/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.0136\n",
      "Epoch 95/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.0228\n",
      "Epoch 96/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.0175\n",
      "Epoch 97/100\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 0.0164\n",
      "Epoch 98/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.0139\n",
      "Epoch 99/100\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 0.0143\n",
      "Epoch 100/100\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 0.0178\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2484eb6ca90>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Setup GRU Model\n",
    "gru_model = Sequential()\n",
    "\n",
    "# First Layer\n",
    "gru_model.add(GRU(units = NUM_NEURONS, return_sequences = True, input_shape = (X_train.shape[1], X_train.shape[2])))\n",
    "gru_model.add(Dropout(DROUP_OUT))\n",
    "\n",
    "# Second Layer\n",
    "gru_model.add(GRU(units = NUM_NEURONS, return_sequences = True))\n",
    "gru_model.add(Dropout(DROUP_OUT))\n",
    "\n",
    "# Third Layer\n",
    "gru_model.add(GRU(units = NUM_NEURONS, return_sequences = True))\n",
    "gru_model.add(Dropout(DROUP_OUT))\n",
    "\n",
    "# Fourth Layer\n",
    "gru_model.add(GRU(units = NUM_NEURONS))\n",
    "gru_model.add(Dropout(DROUP_OUT))\n",
    "\n",
    "# Output Layer\n",
    "gru_model.add(Dense(forward_days))\n",
    "\n",
    "# Train Model\n",
    "gru_model.compile(loss='mean_squared_error', optimizer='rmsprop')\n",
    "\n",
    "gru_model.fit(X_train, Y_train, epochs = EPOCHES, batch_size = BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carry Out Validation Predictions\n",
    "Xm1 = lstm_model.predict(X_validation)\n",
    "Xm2 = gru_model.predict(X_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_validation = Y_validation.reshape(-1,1)\n",
    "m2_Y_validation = scaler.inverse_transform(Y_validation)\n",
    "Y_validation.reshape(-1,1)\n",
    "\n",
    "m1_prediction = scaler.inverse_transform(Xm1)\n",
    "m2_prediction = scaler.inverse_transform(Xm2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carry out sub-model predictions.\n",
    "Xmt1 = lstm_model.predict(X_test)\n",
    "\n",
    "Xmt2 = gru_model.predict(X_test)\n",
    "\n",
    "Y_test.reshape(-1, 1)\n",
    "\n",
    "m1_x_test = scaler.inverse_transform(Xmt1)\n",
    "m2_x_test = scaler.inverse_transform(Xmt2)\n",
    "\n",
    "Y_test = Y_test.reshape(-1,1)\n",
    "m2_Y_test = scaler.inverse_transform(Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTM MSE:  666.9750940829582\n"
     ]
    }
   ],
   "source": [
    "lstm_model_mse = mean_squared_error(m1_x_test, m2_Y_test)\n",
    "print(\"LSTM MSE: \", lstm_model_mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GRU MSE:  660.2778615927535\n"
     ]
    }
   ],
   "source": [
    "gru_model_mse = mean_squared_error(m2_x_test, m2_Y_test)\n",
    "print(\"GRU MSE: \", gru_model_mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate generic sequential model.\n",
    "dff_output_model = Sequential()\n",
    "\n",
    "# Desired activation function.\n",
    "activ_func = \"relu\"\n",
    "\n",
    "# Set input layer and size.\n",
    "dff_output_model.add(Flatten(input_shape=(2,)))\n",
    "\n",
    "# Hidden Layer 1\n",
    "dff_output_model.add(Dense(18, activation = activ_func))\n",
    "\n",
    "# Hidden Layer 2\n",
    "dff_output_model.add(Dense(9, activation = activ_func))\n",
    "\n",
    "# Hidden Layer 3\n",
    "dff_output_model.add(Dense(2, activation = activ_func))\n",
    "\n",
    "# Output Layer\n",
    "dff_output_model.add(Dense(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize X validation data.\n",
    "scaler = MinMaxScaler()\n",
    "normalized_x_validation1 = scaler.fit_transform(m1_prediction)\n",
    "normalized_x_validation2 = scaler.fit_transform(m2_prediction)\n",
    "\n",
    "# Normalize Y validation data.\n",
    "normalized_y_validation = scaler.fit_transform(m2_Y_validation)\n",
    "\n",
    "# Concate training data.\n",
    "level1_train_data = np.concatenate((normalized_x_validation1, normalized_x_validation2), axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "7/7 [==============================] - 1s 831us/step - loss: 0.2239 - mae: 0.3917\n",
      "Epoch 2/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.3208 - mae: 0.4683\n",
      "Epoch 3/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.2517 - mae: 0.3652\n",
      "Epoch 4/100\n",
      "7/7 [==============================] - 0s 997us/step - loss: 0.1992 - mae: 0.3691\n",
      "Epoch 5/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.2069 - mae: 0.3628\n",
      "Epoch 6/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.2623 - mae: 0.4332\n",
      "Epoch 7/100\n",
      "7/7 [==============================] - 0s 997us/step - loss: 0.2459 - mae: 0.4026\n",
      "Epoch 8/100\n",
      "7/7 [==============================] - 0s 998us/step - loss: 0.1599 - mae: 0.2946\n",
      "Epoch 9/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.2130 - mae: 0.3530\n",
      "Epoch 10/100\n",
      "7/7 [==============================] - 0s 997us/step - loss: 0.2274 - mae: 0.3506\n",
      "Epoch 11/100\n",
      "7/7 [==============================] - 0s 838us/step - loss: 0.2875 - mae: 0.4190\n",
      "Epoch 12/100\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.1722 - mae: 0.3078\n",
      "Epoch 13/100\n",
      "7/7 [==============================] - 0s 998us/step - loss: 0.2226 - mae: 0.3795\n",
      "Epoch 14/100\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.1794 - mae: 0.3468\n",
      "Epoch 15/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.2256 - mae: 0.3758\n",
      "Epoch 16/100\n",
      "7/7 [==============================] - 0s 997us/step - loss: 0.2319 - mae: 0.3607\n",
      "Epoch 17/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.1930 - mae: 0.3431\n",
      "Epoch 18/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.2201 - mae: 0.3726\n",
      "Epoch 19/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.1360 - mae: 0.2916\n",
      "Epoch 20/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.1844 - mae: 0.3496\n",
      "Epoch 21/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.1727 - mae: 0.3326\n",
      "Epoch 22/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.1240 - mae: 0.2788\n",
      "Epoch 23/100\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.2701 - mae: 0.4194\n",
      "Epoch 24/100\n",
      "7/7 [==============================] - 0s 998us/step - loss: 0.2186 - mae: 0.3803\n",
      "Epoch 25/100\n",
      "7/7 [==============================] - 0s 998us/step - loss: 0.2971 - mae: 0.4495\n",
      "Epoch 26/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.1244 - mae: 0.2717\n",
      "Epoch 27/100\n",
      "7/7 [==============================] - 0s 998us/step - loss: 0.2404 - mae: 0.3746\n",
      "Epoch 28/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.1922 - mae: 0.3420\n",
      "Epoch 29/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.1280 - mae: 0.2675\n",
      "Epoch 30/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.1505 - mae: 0.3053\n",
      "Epoch 31/100\n",
      "7/7 [==============================] - 0s 997us/step - loss: 0.2714 - mae: 0.4260\n",
      "Epoch 32/100\n",
      "7/7 [==============================] - 0s 836us/step - loss: 0.1650 - mae: 0.3341\n",
      "Epoch 33/100\n",
      "7/7 [==============================] - 0s 750us/step - loss: 0.1868 - mae: 0.3440\n",
      "Epoch 34/100\n",
      "7/7 [==============================] - 0s 997us/step - loss: 0.2265 - mae: 0.3907\n",
      "Epoch 35/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.2301 - mae: 0.3911\n",
      "Epoch 36/100\n",
      "7/7 [==============================] - 0s 998us/step - loss: 0.1695 - mae: 0.3287\n",
      "Epoch 37/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.1852 - mae: 0.3535\n",
      "Epoch 38/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.1721 - mae: 0.3332\n",
      "Epoch 39/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.0992 - mae: 0.2347\n",
      "Epoch 40/100\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.1732 - mae: 0.3147\n",
      "Epoch 41/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.1389 - mae: 0.2737\n",
      "Epoch 42/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.1383 - mae: 0.3171\n",
      "Epoch 43/100\n",
      "7/7 [==============================] - 0s 840us/step - loss: 0.1630 - mae: 0.3223\n",
      "Epoch 44/100\n",
      "7/7 [==============================] - 0s 997us/step - loss: 0.1380 - mae: 0.3006\n",
      "Epoch 45/100\n",
      "7/7 [==============================] - 0s 997us/step - loss: 0.1497 - mae: 0.3008\n",
      "Epoch 46/100\n",
      "7/7 [==============================] - 0s 998us/step - loss: 0.1129 - mae: 0.2514\n",
      "Epoch 47/100\n",
      "7/7 [==============================] - 0s 999us/step - loss: 0.1371 - mae: 0.2996\n",
      "Epoch 48/100\n",
      "7/7 [==============================] - 0s 932us/step - loss: 0.1744 - mae: 0.3391\n",
      "Epoch 49/100\n",
      "7/7 [==============================] - 0s 828us/step - loss: 0.1633 - mae: 0.3239\n",
      "Epoch 50/100\n",
      "7/7 [==============================] - 0s 997us/step - loss: 0.0811 - mae: 0.2437\n",
      "Epoch 51/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.0947 - mae: 0.2454\n",
      "Epoch 52/100\n",
      "7/7 [==============================] - 0s 998us/step - loss: 0.1214 - mae: 0.2761\n",
      "Epoch 53/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.1097 - mae: 0.2667\n",
      "Epoch 54/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.0803 - mae: 0.2309\n",
      "Epoch 55/100\n",
      "7/7 [==============================] - 0s 997us/step - loss: 0.1520 - mae: 0.3018\n",
      "Epoch 56/100\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.1134 - mae: 0.2655\n",
      "Epoch 57/100\n",
      "7/7 [==============================] - 0s 997us/step - loss: 0.1004 - mae: 0.2619\n",
      "Epoch 58/100\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.1497 - mae: 0.3120\n",
      "Epoch 59/100\n",
      "7/7 [==============================] - 0s 997us/step - loss: 0.1341 - mae: 0.2994\n",
      "Epoch 60/100\n",
      "7/7 [==============================] - 0s 665us/step - loss: 0.1620 - mae: 0.3399\n",
      "Epoch 61/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.1033 - mae: 0.2624\n",
      "Epoch 62/100\n",
      "7/7 [==============================] - 0s 665us/step - loss: 0.0622 - mae: 0.2137\n",
      "Epoch 63/100\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.1190 - mae: 0.2942\n",
      "Epoch 64/100\n",
      "7/7 [==============================] - 0s 665us/step - loss: 0.1481 - mae: 0.3032\n",
      "Epoch 65/100\n",
      "7/7 [==============================] - 0s 832us/step - loss: 0.1057 - mae: 0.2625\n",
      "Epoch 66/100\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.1352 - mae: 0.3091\n",
      "Epoch 67/100\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.1249 - mae: 0.2915\n",
      "Epoch 68/100\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.0696 - mae: 0.2221\n",
      "Epoch 69/100\n",
      "7/7 [==============================] - 0s 997us/step - loss: 0.1103 - mae: 0.2740\n",
      "Epoch 70/100\n",
      "7/7 [==============================] - 0s 833us/step - loss: 0.1046 - mae: 0.2569\n",
      "Epoch 71/100\n",
      "7/7 [==============================] - 0s 695us/step - loss: 0.1451 - mae: 0.3182\n",
      "Epoch 72/100\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.1032 - mae: 0.2666\n",
      "Epoch 73/100\n",
      "7/7 [==============================] - 0s 997us/step - loss: 0.1089 - mae: 0.2771\n",
      "Epoch 74/100\n",
      "7/7 [==============================] - 0s 839us/step - loss: 0.1181 - mae: 0.2894\n",
      "Epoch 75/100\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.1151 - mae: 0.2765\n",
      "Epoch 76/100\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.1438 - mae: 0.3178\n",
      "Epoch 77/100\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.0947 - mae: 0.2414\n",
      "Epoch 78/100\n",
      "7/7 [==============================] - 0s 830us/step - loss: 0.0954 - mae: 0.2504\n",
      "Epoch 79/100\n",
      "7/7 [==============================] - 0s 737us/step - loss: 0.1284 - mae: 0.3015\n",
      "Epoch 80/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.0812 - mae: 0.2294\n",
      "Epoch 81/100\n",
      "7/7 [==============================] - 0s 665us/step - loss: 0.0977 - mae: 0.2553\n",
      "Epoch 82/100\n",
      "7/7 [==============================] - 0s 999us/step - loss: 0.0691 - mae: 0.2176\n",
      "Epoch 83/100\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.0838 - mae: 0.2398\n",
      "Epoch 84/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.1075 - mae: 0.2760\n",
      "Epoch 85/100\n",
      "7/7 [==============================] - 0s 836us/step - loss: 0.1115 - mae: 0.2689\n",
      "Epoch 86/100\n",
      "7/7 [==============================] - 0s 1000us/step - loss: 0.1193 - mae: 0.2915\n",
      "Epoch 87/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 665us/step - loss: 0.1301 - mae: 0.2999\n",
      "Epoch 88/100\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.1210 - mae: 0.2924\n",
      "Epoch 89/100\n",
      "7/7 [==============================] - 0s 667us/step - loss: 0.1361 - mae: 0.3087\n",
      "Epoch 90/100\n",
      "7/7 [==============================] - 0s 889us/step - loss: 0.0727 - mae: 0.2186\n",
      "Epoch 91/100\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.0813 - mae: 0.2384\n",
      "Epoch 92/100\n",
      "7/7 [==============================] - 0s 665us/step - loss: 0.0808 - mae: 0.2304\n",
      "Epoch 93/100\n",
      "7/7 [==============================] - 0s 1ms/step - loss: 0.1060 - mae: 0.2749\n",
      "Epoch 94/100\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.0662 - mae: 0.2137\n",
      "Epoch 95/100\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.0830 - mae: 0.2398\n",
      "Epoch 96/100\n",
      "7/7 [==============================] - 0s 665us/step - loss: 0.0786 - mae: 0.2288\n",
      "Epoch 97/100\n",
      "7/7 [==============================] - 0s 834us/step - loss: 0.0686 - mae: 0.2051\n",
      "Epoch 98/100\n",
      "7/7 [==============================] - 0s 665us/step - loss: 0.0848 - mae: 0.2221\n",
      "Epoch 99/100\n",
      "7/7 [==============================] - 0s 831us/step - loss: 0.0757 - mae: 0.2091\n",
      "Epoch 100/100\n",
      "7/7 [==============================] - 0s 784us/step - loss: 0.1027 - mae: 0.2504\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2485be2bd00>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compile model.\n",
    "dff_output_model.compile(optimizer='rmsprop',loss='mean_squared_error', metrics=['mae'])\n",
    "\n",
    "# Fit model to training data.\n",
    "dff_output_model.fit(level1_train_data, normalized_y_validation, epochs = 100, batch_size = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Normalize test data.\n",
    "normalized_x_test1 = scaler.fit_transform(m1_x_test)\n",
    "normalized_x_test2 = scaler.fit_transform(m2_x_test)\n",
    "\n",
    "# Concatanate the test data.\n",
    "level1_test_data = np.concatenate((normalized_x_test1, normalized_x_test2), axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xt3 = dff_output_model.predict(level1_test_data)\n",
    "\n",
    "predicted_stock_price = scaler.inverse_transform(Xt3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Blending Ensemble MSE:  421.8238557903405\n"
     ]
    }
   ],
   "source": [
    "mse = mean_squared_error(predicted_stock_price, m2_Y_test)\n",
    "print(\"Blending Ensemble MSE: \", mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_classifier(values, debug=False):\n",
    "    binary_results = np.zeros(len(values) - 1)\n",
    "    for idx, val in enumerate(values):\n",
    "        if idx < 1:\n",
    "            continue\n",
    "        if values[idx] > values[idx - 1]:\n",
    "            binary_results[idx - 1] = 1\n",
    "            if debug:\n",
    "                print(f'Increase: {values[idx]} vs {values[idx - 1]}')\n",
    "        else:\n",
    "            if debug:\n",
    "                print(f'Decrease: {values[idx]} vs {values[idx - 1]}')\n",
    "            \n",
    "    return binary_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_mda(true_direction, predicted_direction, debug=False):\n",
    "    correct_predictions = 0\n",
    "    for idx, val in enumerate(true_direction):\n",
    "        if debug:\n",
    "            print(f'Predicted: {prediction_binary[idx]} vs actual {true_direction[idx]}')\n",
    "        if predicted_direction[idx] == true_direction[idx]:\n",
    "            correct_predictions = correct_predictions + 1\n",
    "    \n",
    "    if debug:\n",
    "        print(f'Correct Predictions: {correct_predictions} out of {len(predicted_direction)}.')\n",
    "    \n",
    "    mda = correct_predictions / len(predicted_direction)\n",
    "    return mda\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall: 0.2\n",
      "Precision: 0.3333333333333333\n",
      "F1 Score: 0.25\n",
      "MDA: 53.84615384615385%\n",
      "Blending Ensemble MSE: 421.8238557903405\n"
     ]
    }
   ],
   "source": [
    "# Output results.\n",
    "prediction_binary = convert_to_classifier(predicted_stock_price, debug=False)\n",
    "test_binary = convert_to_classifier(m2_Y_test, debug=False)\n",
    "recall = recall_score(test_binary, prediction_binary)\n",
    "precision = precision_score(test_binary, prediction_binary)\n",
    "f1_score = f1_score(test_binary, prediction_binary)\n",
    "mda = calc_mda(test_binary, prediction_binary, debug=False)\n",
    "print(f'Recall: {recall}\\nPrecision: {precision}\\nF1 Score: {f1_score}\\nMDA: {mda * 100}%\\nBlending Ensemble MSE: {mse}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
